| nums | Public Models                                                | version                                                      | Common_Sense_Reasoning_2 | Numerical_Calculation | Text_Translation | Code_Reasoning | score  |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------ | --------------------- | ---------------- | -------------- | ------ |
| 1    | [BLIP-2](https://arxiv.org/pdf/2301.12597.pdf)               | [Flant5xxl](https://github.com/salesforce/LAVIS/tree/main/projects/blip2) | 110.00                   | 40.00                 | 65.00            | 75.00          | 290.00 |
| 2    | [MiniGPT-4](https://arxiv.org/pdf/2304.10592.pdf)            | [Vicuna-13B](https://github.com/Vision-CAIR/MiniGPT-4)       | 59.29                    | 45.00                 | 0.00             | 40.00          | 144.29 |
| 3    | [mPLUG-Owl](https://arxiv.org/pdf/2304.14178.pdf)            | [LLaMA-7B](https://huggingface.co/MAGAer13/mplug-owl-llama-7b) | 78.57                    | 60.00                 | 80.00            | 57.50          | 276.07 |
| 4    | [ImageBind_LLM](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main) | [LLaMA-7B](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main/imagebind_LLM) | 48.57                    | 55.00                 | 50.00            | 60.00          | 213.57 |
| 5    | [LLaMA-Adapter V2](https://arxiv.org/pdf/2304.15010.pdf)     | [LLaMA-Adapter-v2.1-7B](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main/llama_adapter_v2_multimodal7b) | 106.43                   | 47.50                 | 112.50           | 90.00          | 356.43 |
| 6    | [InstructBLIP](https://arxiv.org/pdf/2305.06500.pdf)         | [FlanT5xxl](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip) | 129.29                   | 40.00                 | 65.00            | 57.50          | 291.79 |
| 7    | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B)        | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B)        | 39.29                    | 45.00                 | 50.00            | 47.50          | 181.79 |
| 8    | [Otter](https://arxiv.org/pdf/2305.03726.pdf)                | [OTTER-Image-MPT7B](https://github.com/Luodian/Otter)        | 106.43                   | 72.50                 | 57.50            | 70.00          | 306.43 |
| 9    | [Multimodal-GPT](https://arxiv.org/pdf/2305.04790.pdf)       | [Multimodal-GPT-9B](https://github.com/open-mmlab/Multimodal-GPT) | 49.29                    | 62.50                 | 60.00            | 55.00          | 226.79 |
| 10   | [PandaGPT](https://arxiv.org/pdf/2305.16355.pdf)             | [Vicuna-7B](https://github.com/yxuansu/PandaGPT)             | 73.57                    | 50.00                 | 57.50            | 47.50          | 228.57 |
| 11   | [LLaVA](https://arxiv.org/pdf/2304.08485.pdf)                | [Vicuna-13B](https://github.com/haotian-liu/LLaVA)           | 127.86                   | 42.50                 | 77.50            | 47.50          | 295.36 |
| 12   | [LaVIN](https://arxiv.org/pdf/2305.15023.pdf)                | [LAVIN-13B](https://github.com/luogen1996/LaVIN)             | 87.14                    | 65.00                 | 47.50            | 50.00          | 249.64 |
| 13   | [VPGTrans](https://arxiv.org/pdf/2305.01278.pdf)             | [Vicuna-7B](https://github.com/VPGTrans/VPGTrans)            | 64.29                    | 50.00                 | 77.50            | 57.50          | 249.29 |
| 14   | [Lynx](https://arxiv.org/pdf/2307.02469.pdf)                 | [Vicuna-7B](https://github.com/bytedance/lynx-llm)           | 110.71                   | 17.50                 | 42.50            | 45.00          | 215.71 |
| 15   | [LRV-Instruction](https://arxiv.org/pdf/2306.14565.pdf)      | [LRV-7B](https://github.com/FuxiaoLiu/LRV-Instruction)       | 100.71                   | 70.00                 | 85.00            | 72.50          | 328.21 |
| 16   | [Cheetor](https://arxiv.org/pdf/2308.04152.pdf)              | [Vicuna-7B](https://github.com/DCDmllm/Cheetah)              | 98.57                    | 77.50                 | 57.50            | 87.50          | 321.07 |
| 17   | [MMICL](https://arxiv.org/pdf/2309.07915.pdf)                | [FlanT5xxl](https://github.com/HaozheZhao/MIC)               | 136.43                   | 82.50                 | 132.50           | 77.50          | 428.93 |
| 18   | [GIT2](https://arxiv.org/pdf/2205.14100.pdf)                 | [VQAv2-finetuned](https://github.com/microsoft/GenerativeImage2Text) | 99.29                    | 50.00                 | 67.50            | 45.00          | 261.79 |
| 19   | [BLIVA](https://arxiv.org/pdf/2308.09936.pdf)                | [FlanT5xxl](https://github.com/mlpc-ucsd/BLIVA)              | 136.43                   | 57.50                 | 77.50            | 60.00          | 331.43 |
| 20   | [Qwen-VL-Chat](https://github.com/QwenLM/Qwen-VL/)           | [Qwen-7B](https://github.com/QwenLM/Qwen-VL)                 | 130.71                   | 40.00                 | 147.50           | 42.50          | 360.71 |
| 21   | [InternLM-XComposer-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM-7B](https://github.com/InternLM/InternLM-XComposer) | 138.57                   | 55.00                 | 112.50           | 85.00          | 391.07 |
| 22   | [WeMM](https://github.com/scenarios/WeMM)                    | [InternLM-7B](https://github.com/scenarios/WeMM)             | 140.00                   | 57.50                 | 130.00           | 117.50         | 445.00 |
| 23   | [Muffin](https://github.com/thunlp/Muffin)                   | [Vicuna-13B](https://github.com/thunlp/Muffin)               | 110.00                   | 45.00                 | 72.50            | 62.50          | 290.00 |
| 24   | [GPT-4V](https://cdn.openai.com/papers/GPTV_System_Card.pdf) | [-](https://cdn.openai.com/papers/GPTV_System_Card.pdf)      | 142.14                   | 130.00                | 75.00            | 170.00         | 517.14 |
| 25   | [SPHINX](https://github.com/Alpha-VLLM/LLaMA2-Accessory/tree/main/SPHINX) | [LLaMA2-13B](https://github.com/Alpha-VLLM/LLaMA2-Accessory/tree/main/SPHINX) | 130.00                   | 55.00                 | 75.00            | 50.00          | 310.00 |
| 26   | [mPLUG-Owl2](https://arxiv.org/pdf/2311.04257.pdf)           | [LLaMA2-7B](https://github.com/X-PLUG/mPLUG-Owl/tree/main/mPLUG-Owl2) | 115.71                   | 35.00                 | 102.50           | 60.00          | 313.21 |
| 27   | [InfMLLM](https://github.com/mightyzau/InfMLLM)              | [Vicuna-13B](https://github.com/mightyzau/InfMLLM)           | 156.43                   | 60.00                 | 77.50            | 75.00          | 368.93 |
| 28   | [LVIS-INSTRUCT4V](https://arxiv.org/pdf/2311.07574.pdf)      | [Vicuna-13B](https://github.com/X2FD/LVIS-INSTRUCT4V)        | 134.29                   | 40.00                 | 70.00            | 42.50          | 286.79 |
| 29   | [ShareGPT4V](https://arxiv.org/pdf/2311.12793.pdf)           | [Vicuna-13B](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V) | 125.71                   | 45.00                 | 80.00            | 52.50          | 303.21 |
| 30   | [DataOptim-LLaVA](https://github.com/BAAI-DCAI/DataOptim)    | [Vicuna-13B](https://github.com/BAAI-DCAI/DataOptim)         | 123.57                   | 47.50                 | 110.00           | 80.00          | 361.07 |
| 31   | [BELLE-VL](https://huggingface.co/BELLE-2/BELLE-VL)          | [Qwen-14B](https://huggingface.co/BELLE-2/BELLE-VL)          | 127.14                   | 47.50                 | 102.50           | 55.00          | 332.14 |
| 32   | [TransCore-M](https://github.com/PCIResearch/TransCore-M)    | [PCITransGPT-13B](https://github.com/PCIResearch/TransCore-M) | 132.14                   | 55.00                 | 55.00            | 72.50          | 314.64 |
| 33   | [Monkey-Chat](https://arxiv.org/pdf/2311.06607.pdf)          | [Qwen-7B](https://github.com/Yuliang-Liu/Monkey)             | 131.43                   | 42.50                 | 137.50           | 90.00          | 401.43 |
| 34   | [Qwen-VL-Plus](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | [-](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | 142.14                   | 85.00                 | 185.00           | 90.00          | 502.14 |
| 35   | [Gemini Pro](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) | [-](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) | 129.29                   | 77.50                 | 145.00           | 85.00          | 436.79 |
| 36   | [Honeybee](https://arxiv.org/pdf/2312.06742.pdf)             | [Vicuna-13B](https://github.com/kakaobrain/honeybee)         | 122.86                   | 57.50                 | 87.50            | 47.50          | 315.36 |
| 37   | [RBDash](https://github.com/RBDash-Team/RBDash)              | [Vicuna-13B](https://github.com/RBDash-Team/RBDash)          | 140.00                   | 67.50                 | 72.50            | 50.00          | 330.00 |
| 38   | [PureMM](https://github.com/Q-MM/PureMM)                     | [Vicuna-13B](https://github.com/Q-MM/PureMM)                 | 137.86                   | 45.00                 | 92.50            | 85.00          | 360.36 |
| 39   | [InternLM-XComposer2-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM2-7B](https://github.com/InternLM/InternLM-XComposer) | 145.71                   | 137.50                | 147.50           | 100.00         | 530.71 |
| 40   | [Qwen-VL-Max](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | [-](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | 148.57                   | 155.00                | 170.00           | 170.00         | 643.57 |
| 41   | [InternVL-Chat-V1.1](https://arxiv.org/pdf/2312.14238.pdf)   | [LLaMA2-13B](https://github.com/OpenGVLab/InternVL/)         | 123.57                   | 70.00                 | 102.50           | 45.00          | 341.07 |
| 42   | [MoE-LLaVA](https://arxiv.org/pdf/2401.15947.pdf)            | [Phi-2.7BÃ—4](https://github.com/PKU-YuanGroup/MoE-LLaVA)     | 117.14                   | 50.00                 | 57.50            | 37.50          | 262.14 |
| 43   | [CogAgent](https://arxiv.org/pdf/2312.08914.pdf)             | [Vicuna-7B](https://github.com/THUDM/CogVLM)                 | 117.14                   | 45.00                 | 62.50            | 50.00          | 274.64 |
| 44   | [CogVLM](https://arxiv.org/pdf/2311.03079.pdf)               | [Vicuna-7B](https://github.com/THUDM/CogVLM)                 | 125.71                   | 60.00                 | 75.00            | 52.50          | 313.21 |
| 45   | [LLaVA-1.6](https://llava-vl.github.io/blog/2024-01-30-llava-1-6/) | [Vicuna-34B](https://github.com/haotian-liu/LLaVA)           | 152.14                   | 72.50                 | 72.50            | 100.00         | 397.14 |
| 46   | [MiniCPM](https://github.com/OpenBMB/MiniCPM/#minicpm-v)     | [MiniCPM-2B](https://github.com/OpenBMB/MiniCPM/#minicpm-v)  | 119.29                   | 47.50                 | 82.50            | 65.00          | 314.29 |
| 47   | [OmniLMM](https://github.com/OpenBMB/MiniCPM/#minicpm-v)     | [Zephyr-7B-beta](https://github.com/OpenBMB/MiniCPM/#minicpm-v) | 127.14                   | 55.00                 | 77.50            | 62.50          | 322.14 |
| 48   | [ChatTruth-7B](https://huggingface.co/mingdali/ChatTruth-7B) | [Qwen-7B](https://huggingface.co/mingdali/ChatTruth-7B)      | 132.86                   | 40.00                 | 162.50           | 52.50          | 387.86 |
| 49   | [Bunny-4B](https://arxiv.org/pdf/2402.11530.pdf)             | [Phi-3-Mini-4K-Instruct](https://github.com/BAAI-DCAI/Bunny) | 123.57                   | 85.00                 | 102.50           | 50.00          | 361.07 |
| 50   | [MindSource-VL-Chat](https://github.com/luogen1996/LLaVA-HR) | [MindSource-7B](https://github.com/luogen1996/LLaVA-HR)      | 136.43                   | 45.00                 | 80.00            | 40.00          | 301.43 |
| 51   | [HyperLLaVA](https://arxiv.org/pdf/2403.13447.pdf)           | [Vicuna-13B](https://github.com/dcdmllm/hyperllava)          | 134.29                   | 37.50                 | 87.50            | 45.00          | 304.29 |
| 52   | [MiniCPM-V-2](https://github.com/OpenBMB/MiniCPM/#minicpm-v) | [MiniCPM-2B](https://github.com/OpenBMB/MiniCPM/#minicpm-v)  | 128.57                   | 32.50                 | 170.00           | 75.00          | 406.07 |
| 53   | [InternVL-Chat-V1.5](https://arxiv.org/pdf/2404.16821)       | [InternLM2-20B](https://github.com/OpenGVLab/InternVL)       | 135.00                   | 125.00                | 185.00           | 105.00         | 550.00 |
| 54   | [360VL](https://github.com/360CVGroup/360VL?tab=readme-ov-file) | [LLaMA3-70B](https://github.com/360CVGroup/360VL?tab=readme-ov-file) | 151.43                   | 70.00                 | 72.50            | 77.50          | 371.43 |
| 55   | [MiniCPM-Llama3-V 2.5](https://github.com/OpenBMB/MiniCPM-V) | [LLaMA3-8B](https://github.com/OpenBMB/MiniCPM-V)            | 150.71                   | 50.00                 | 140.00           | 60.00          | 400.71 |
| 56   | [JT-VL-Chat](https://github.com/jiutiancv/JT-VL-Chat)        | [-](https://github.com/jiutiancv/JT-VL-Chat)                 | 122.14                   | 67.50                 | 105.00           | 45.00          | 339.64 |
| 57   | [Bunny-8B](https://github.com/BAAI-DCAI/Bunny)               | [LLaMA3-8B](https://github.com/BAAI-DCAI/Bunny)              | 140.00                   | 75.00                 | 95.00            | 57.50          | 367.50 |