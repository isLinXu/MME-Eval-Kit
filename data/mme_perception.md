| nums | Public Models                                                | version                                                      | existence | count  | position | color  | posters_200 | cast_200 | scene_200 | landmark_200 | artwork_200 | OCR    | score   |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------- | ------ | -------- | ------ | ----------- | -------- | --------- | ------------ | ----------- | ------ | ------- |
| 1    | [BLIP-2](https://arxiv.org/pdf/2301.12597.pdf)               | [Flant5xxl](https://github.com/salesforce/LAVIS/tree/main/projects/blip2) | 160.00    | 135.00 | 73.33    | 148.33 | 141.84      | 105.59   | 145.25    | 138.00       | 136.50      | 110.00 | 1293.84 |
| 2    | [MiniGPT-4](https://arxiv.org/pdf/2304.10592.pdf)            | [Vicuna-13B](https://github.com/Vision-CAIR/MiniGPT-4)       | 68.33     | 55.00  | 43.33    | 75.00  | 41.84       | 54.41    | 71.75     | 54.00        | 60.50       | 57.50  | 581.66  |
| 3    | [mPLUG-Owl](https://arxiv.org/pdf/2304.14178.pdf)            | [LLaMA-7B](https://huggingface.co/MAGAer13/mplug-owl-llama-7b) | 120.00    | 50.00  | 50.00    | 55.00  | 136.05      | 100.29   | 135.50    | 159.25       | 96.25       | 65.00  | 967.34  |
| 4    | [ImageBind_LLM](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main) | [LLaMA-7B](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main/imagebind_LLM) | 128.33    | 60.00  | 46.67    | 73.33  | 64.97       | 76.47    | 113.25    | 62.00        | 70.75       | 80.00  | 775.77  |
| 5    | [LLaMA-Adapter V2](https://arxiv.org/pdf/2304.15010.pdf)     | [LLaMA-Adapter-v2.1-7B](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main/llama_adapter_v2_multimodal7b) | 185.00    | 133.33 | 56.67    | 118.33 | 147.96      | 136.76   | 156.25    | 167.84       | 123.75      | 102.50 | 1328.39 |
| 6    | [InstructBLIP](https://arxiv.org/pdf/2305.06500.pdf)         | [FlanT5xxl](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip) | 185.00    | 143.33 | 66.67    | 153.33 | 123.81      | 101.18   | 153.00    | 79.75        | 134.25      | 72.50  | 1212.82 |
| 7    | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B)        | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B)        | 85.00     | 50.00  | 48.33    | 55.00  | 65.99       | 53.24    | 146.25    | 83.75        | 75.25       | 42.50  | 705.31  |
| 8    | [Otter](https://arxiv.org/pdf/2305.03726.pdf)                | [OTTER-Image-MPT7B](https://github.com/Luodian/Otter)        | 195.00    | 88.33  | 86.67    | 113.33 | 138.78      | 172.65   | 158.75    | 137.25       | 129.00      | 72.50  | 1292.26 |
| 9    | [Multimodal-GPT](https://arxiv.org/pdf/2305.04790.pdf)       | [Multimodal-GPT-9B](https://github.com/open-mmlab/Multimodal-GPT) | 61.67     | 55.00  | 58.33    | 68.33  | 57.82       | 73.82    | 68.00     | 69.75        | 59.50       | 82.50  | 654.72  |
| 10   | [PandaGPT](https://arxiv.org/pdf/2305.16355.pdf)             | [Vicuna-7B](https://github.com/yxuansu/PandaGPT)             | 70.00     | 50.00  | 50.00    | 50.00  | 76.53       | 57.06    | 118.00    | 69.75        | 51.25       | 50.00  | 642.59  |
| 11   | [LLaVA](https://arxiv.org/pdf/2304.08485.pdf)                | [Vicuna-13B](https://github.com/haotian-liu/LLaVA)           | 185.00    | 155.00 | 133.33   | 170.00 | 160.54      | 152.94   | 161.25    | 170.50       | 117.75      | 125.00 | 1531.31 |
| 12   | [LaVIN](https://arxiv.org/pdf/2305.15023.pdf)                | [LAVIN-13B](https://github.com/luogen1996/LaVIN)             | 185.00    | 88.33  | 63.33    | 75.00  | 79.59       | 47.35    | 136.75    | 93.50        | 87.25       | 107.50 | 963.60  |
| 13   | [VPGTrans](https://arxiv.org/pdf/2305.01278.pdf)             | [Vicuna-7B](https://github.com/VPGTrans/VPGTrans)            | 70.00     | 85.00  | 63.33    | 73.33  | 84.01       | 53.53    | 141.75    | 64.75        | 77.25       | 77.50  | 790.45  |
| 14   | [Lynx](https://arxiv.org/pdf/2307.02469.pdf)                 | [Vicuna-7B](https://github.com/bytedance/lynx-llm)           | 195.00    | 151.67 | 90.00    | 170.00 | 124.83      | 118.24   | 164.50    | 162.00       | 119.50      | 77.50  | 1373.24 |
| 15   | [LRV-Instruction](https://arxiv.org/pdf/2306.14565.pdf)      | [LRV-7B](https://github.com/FuxiaoLiu/LRV-Instruction)       | 165.00    | 111.67 | 86.67    | 165.00 | 139.04      | 112.65   | 147.98    | 160.53       | 101.25      | 110.00 | 1299.79 |
| 16   | [Cheetor](https://arxiv.org/pdf/2308.04152.pdf)              | [Vicuna-7B](https://github.com/DCDmllm/Cheetah)              | 180.00    | 96.67  | 80.00    | 116.67 | 147.28      | 164.12   | 156.00    | 145.73       | 113.50      | 100.00 | 1299.97 |
| 17   | [MMICL](https://arxiv.org/pdf/2309.07915.pdf)                | [FlanT5xxl](https://github.com/HaozheZhao/MIC)               | 170.00    | 160.00 | 81.67    | 156.67 | 146.26      | 141.76   | 153.75    | 136.13       | 135.50      | 100.00 | 1381.74 |
| 18   | [GIT2](https://arxiv.org/pdf/2205.14100.pdf)                 | [VQAv2-finetuned](https://github.com/microsoft/GenerativeImage2Text) | 190.00    | 118.33 | 96.67    | 158.33 | 112.59      | 145.88   | 158.50    | 140.50       | 146.25      | 65.00  | 1332.05 |
| 19   | [BLIVA](https://arxiv.org/pdf/2308.09936.pdf)                | [FlanT5xxl](https://github.com/mlpc-ucsd/BLIVA)              | 180.00    | 138.33 | 81.67    | 180.00 | 155.10      | 140.88   | 151.50    | 89.50        | 133.25      | 87.50  | 1337.73 |
| 20   | [Qwen-VL-Chat](https://github.com/QwenLM/Qwen-VL/)           | [Qwen-7B](https://github.com/QwenLM/Qwen-VL)                 | 158.33    | 150.00 | 128.33   | 170.00 | 178.57      | 120.59   | 152.25    | 164.00       | 125.50      | 140.00 | 1487.57 |
| 21   | [InternLM-XComposer-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM-7B](https://github.com/InternLM/InternLM-XComposer) | 190.00    | 158.33 | 126.67   | 165.00 | 161.90      | 150.29   | 159.75    | 165.25       | 126.25      | 125.00 | 1528.44 |
| 22   | [WeMM](https://github.com/scenarios/WeMM)                    | [InternLM-7B](https://github.com/scenarios/WeMM)             | 195.00    | 140.00 | 126.67   | 168.33 | 160.54      | 179.12   | 176.25    | 172.25       | 156.00      | 147.50 | 1621.66 |
| 23   | [Muffin](https://github.com/thunlp/Muffin)                   | [Vicuna-13B](https://github.com/thunlp/Muffin)               | 195.00    | 163.33 | 66.67    | 165.00 | 137.76      | 81.76    | 151.25    | 146.25       | 116.50      | 57.50  | 1281.02 |
| 24   | [GPT-4V](https://cdn.openai.com/papers/GPTV_System_Card.pdf) | [-](https://cdn.openai.com/papers/GPTV_System_Card.pdf)      | 190.00    | 160.00 | 95.00    | 150.00 | 192.18      | 0.00     | 151.00    | 138.25       | 148.00      | 185.00 | 1409.43 |
| 25   | [SPHINX](https://github.com/Alpha-VLLM/LLaMA2-Accessory/tree/main/SPHINX) | [LLaMA2-13B](https://github.com/Alpha-VLLM/LLaMA2-Accessory/tree/main/SPHINX) | 195.00    | 160.00 | 153.33   | 160.00 | 164.29      | 177.94   | 160.00    | 168.09       | 134.00      | 87.50  | 1560.15 |
| 26   | [mPLUG-Owl2](https://arxiv.org/pdf/2311.04257.pdf)           | [LLaMA2-7B](https://github.com/X-PLUG/mPLUG-Owl/tree/main/mPLUG-Owl2) | 185.00    | 155.00 | 88.33    | 150.00 | 160.20      | 164.41   | 153.25    | 157.25       | 134.25      | 102.50 | 1450.19 |
| 27   | [InfMLLM](https://github.com/infly-ai/INF-MLLM)              | [Vicuna-13B](https://github.com/infly-ai/INF-MLLM)           | 195.00    | 145.00 | 170.00   | 195.00 | 183.33      | 164.41   | 176.75    | 166.75       | 167.50      | 110.00 | 1673.75 |
| 28   | [LVIS-INSTRUCT4V](https://arxiv.org/pdf/2311.07574.pdf)      | [Vicuna-13B](https://github.com/X2FD/LVIS-INSTRUCT4V)        | 195.00    | 160.00 | 128.33   | 180.00 | 162.59      | 161.47   | 163.25    | 161.50       | 130.25      | 132.50 | 1574.89 |
| 29   | [ShareGPT4V](https://arxiv.org/pdf/2311.12793.pdf)           | [Vicuna-13B](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V) | 190.00    | 165.00 | 153.33   | 185.00 | 169.05      | 153.82   | 168.00    | 174.00       | 128.00      | 132.50 | 1618.70 |
| 30   | [DataOptim-LLaVA](https://github.com/BAAI-DCAI/DataOptim)    | [Vicuna-13B](https://github.com/BAAI-DCAI/DataOptim)         | 190.00    | 165.00 | 121.67   | 155.00 | 169.73      | 159.41   | 166.50    | 160.00       | 113.75      | 162.50 | 1563.56 |
| 31   | [BELLE-VL](https://huggingface.co/BELLE-2/BELLE-VL)          | [Qwen-14B](https://huggingface.co/BELLE-2/BELLE-VL)          | 190.00    | 150.00 | 130.00   | 175.00 | 166.33      | 136.76   | 156.25    | 174.00       | 139.50      | 177.50 | 1595.34 |
| 32   | [TransCore-M](https://github.com/PCIResearch/TransCore-M)    | [PCITransGPT-13B](https://github.com/PCIResearch/TransCore-M) | 190.00    | 165.00 | 136.67   | 185.00 | 160.20      | 145.29   | 161.00    | 159.25       | 130.75      | 155.00 | 1588.16 |
| 33   | [Monkey-Chat](https://arxiv.org/pdf/2311.06607.pdf)          | [Qwen-7B](https://github.com/Yuliang-Liu/Monkey)             | 185.00    | 150.00 | 118.33   | 185.00 | 178.91      | 142.65   | 161.75    | 176.50       | 144.25      | 80.00  | 1522.39 |
| 34   | [Qwen-VL-Plus](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | [-](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | 175.00    | 153.33 | 161.67   | 180.00 | 181.63      | 184.12   | 151.00    | 191.00       | 156.00      | 147.50 | 1681.25 |
| 35   | [Gemini Pro](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) | [-](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) | 175.00    | 131.67 | 90.00    | 163.33 | 164.97      | 147.35   | 144.75    | 158.75       | 135.75      | 185.00 | 1496.57 |
| 36   | [Honeybee](https://arxiv.org/pdf/2312.06742.pdf)             | [Vicuna-13B](https://github.com/kakaobrain/honeybee)         | 185.00    | 170.00 | 155.00   | 180.00 | 170.07      | 177.06   | 162.00    | 172.25       | 134.75      | 155.00 | 1661.13 |
| 37   | [RBDash](https://github.com/RBDash-Team/RBDash)              | [Vicuna-13B](https://github.com/RBDash-Team/RBDash)          | 195.00    | 173.33 | 138.33   | 190.00 | 165.99      | 170.00   | 160.25    | 174.25       | 140.50      | 102.50 | 1610.15 |
| 38   | [PureMM](https://github.com/Q-MM/PureMM)                     | [Vicuna-13B](https://github.com/Q-MM/PureMM)                 | 188.33    | 150.00 | 123.33   | 170.00 | 191.50      | 182.35   | 162.75    | 172.25       | 183.50      | 162.50 | 1686.52 |
| 39   | [InternLM-XComposer2-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM2-7B](https://github.com/InternLM/InternLM-XComposer) | 195.00    | 160.00 | 163.33   | 195.00 | 171.09      | 153.82   | 164.75    | 176.00       | 185.50      | 147.50 | 1712.00 |
| 40   | [Qwen-VL-Max](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | [-](https://help.aliyun.com/zh/dashscope/developer-reference/vl-plus-quick-start) | 183.33    | 166.67 | 176.67   | 180.00 | 187.76      | 184.12   | 173.00    | 187.50       | 166.00      | 185.00 | 1790.04 |
| 41   | [InternVL-Chat-V1.1](https://arxiv.org/pdf/2312.14238.pdf)   | [LLaMA2-13B](https://github.com/OpenGVLab/InternVL/)         | 185.00    | 173.33 | 163.33   | 190.00 | 161.22      | 154.71   | 155.75    | 168.00       | 143.50      | 177.50 | 1672.35 |
| 42   | [MoE-LLaVA](https://arxiv.org/pdf/2401.15947.pdf)            | [Phi-2.7BÃ—4](https://github.com/PKU-YuanGroup/MoE-LLaVA)     | 180.00    | 155.00 | 118.33   | 190.00 | 99.32       | 147.94   | 154.50    | 148.25       | 105.50      | 132.50 | 1431.34 |
| 43   | [CogAgent](https://arxiv.org/pdf/2312.08914.pdf)             | [Vicuna-7B](https://github.com/THUDM/CogVLM)                 | 185.00    | 180.00 | 135.00   | 160.00 | 167.35      | 147.94   | 154.25    | 172.00       | 116.25      | 80.00  | 1497.79 |
| 44   | [CogVLM](https://arxiv.org/pdf/2311.03079.pdf)               | [Vicuna-7B](https://github.com/THUDM/CogVLM)                 | 195.00    | 165.00 | 103.33   | 160.00 | 146.94      | 115.29   | 159.25    | 158.00       | 88.75       | 147.50 | 1439.07 |
| 45   | [LLaVA-1.6](https://llava-vl.github.io/blog/2024-01-30-llava-1-6/) | [Vicuna-34B](https://github.com/haotian-liu/LLaVA)           | 190.00    | 170.00 | 138.33   | 195.00 | 169.39      | 160.00   | 164.50    | 165.25       | 139.00      | 140.00 | 1631.47 |
| 46   | [MiniCPM](https://github.com/OpenBMB/MiniCPM/#minicpm-v)     | [MiniCPM-2B](https://github.com/OpenBMB/MiniCPM/#minicpm-v)  | 190.00    | 130.00 | 93.33    | 158.33 | 158.50      | 155.59   | 157.75    | 167.75       | 130.75      | 110.00 | 1452.01 |
| 47   | [OmniLMM](https://github.com/OpenBMB/MiniCPM/#minicpm-v)     | [Zephyr-7B-beta](https://github.com/OpenBMB/MiniCPM/#minicpm-v) | 190.00    | 165.00 | 131.67   | 180.00 | 171.43      | 172.06   | 146.25    | 175.25       | 150.25      | 155.00 | 1636.90 |
| 48   | [ChatTruth-7B](https://huggingface.co/mingdali/ChatTruth-7B) | [Qwen-7B](https://huggingface.co/mingdali/ChatTruth-7B)      | 195.00    | 160.00 | 158.33   | 195.00 | 174.15      | 177.65   | 167.75    | 185.75       | 159.75      | 162.50 | 1735.88 |
| 49   | [Bunny-4B](https://arxiv.org/pdf/2402.11530.pdf)             | [Phi-3-Mini-4K-Instruct](https://github.com/BAAI-DCAI/Bunny) | 190.00    | 165.80 | 131.67   | 170.00 | 150.34      | 151.76   | 163.50    | 167.50       | 136.75      | 155.00 | 1581.52 |
| 50   | [MindSource-VL-Chat](https://github.com/luogen1996/LLaVA-HR) | [MindSource-7B](https://github.com/luogen1996/LLaVA-HR)      | 195.00    | 170.00 | 146.67   | 180.00 | 155.10      | 126.47   | 161.75    | 150.75       | 119.75      | 162.50 | 1567.99 |
| 51   | [HyperLLaVA](https://arxiv.org/pdf/2403.13447.pdf)           | [Vicuna-13B](https://github.com/dcdmllm/hyperllava)          | 190.00    | 160.00 | 128.33   | 180.00 | 164.97      | 162.06   | 166.50    | 172.00       | 119.25      | 132.50 | 1575.61 |
| 52   | [MiniCPM-V-2](https://github.com/OpenBMB/MiniCPM/#minicpm-v) | [MiniCPM-2B](https://github.com/OpenBMB/MiniCPM/#minicpm-v)  | 195.00    | 133.33 | 86.67    | 145.00 | 165.31      | 140.88   | 154.25    | 175.00       | 145.25      | 102.50 | 1443.19 |
| 53   | [InternVL-Chat-V1.5](https://arxiv.org/pdf/2404.16821)       | [InternLM2-20B](https://github.com/OpenGVLab/InternVL)       | 190.00    | 175.00 | 166.67   | 178.33 | 173.81      | 138.53   | 154.75    | 177.75       | 143.00      | 140.00 | 1637.84 |
| 54   | [360VL](https://github.com/360CVGroup/360VL?tab=readme-ov-file) | [LLaMA3-70B](https://github.com/360CVGroup/360VL?tab=readme-ov-file) | 190.00    | 160.80 | 155.00   | 185.00 | 176.87      | 168.24   | 164.75    | 177.25       | 131.25      | 132.50 | 1640.86 |
| 55   | [MiniCPM-Llama3-V 2.5](https://github.com/OpenBMB/MiniCPM-V) | [LLaMA3-8B](https://github.com/OpenBMB/MiniCPM-V)            | 200.00    | 168.33 | 136.67   | 165.00 | 175.85      | 157.94   | 153.75    | 177.25       | 144.50      | 140.00 | 1619.29 |
| 56   | [JT-VL-Chat](https://github.com/jiutiancv/JT-VL-Chat)        | [-](https://github.com/jiutiancv/JT-VL-Chat)                 | 185.00    | 173.33 | 145.00   | 175.00 | 168.71      | 161.47   | 157.75    | 173.50       | 132.75      | 170.00 | 1642.51 |
| 57   | [Bunny-8B](https://github.com/BAAI-DCAI/Bunny)               | [LLaMA3-8B](https://github.com/BAAI-DCAI/Bunny)              | 195.00    | 165.00 | 135.00   | 195.00 | 167.35      | 175.29   | 153.75    | 170.25       | 132.50      | 155.00 | 1644.14 |